{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to study and understand the impact of different variables on the movements of crude oil spot prices. We hope to then build a model that is capable of predicting oil price movements in the near and medium term. \n",
    "\n",
    "Or main source of data is is the Energy Information Agency's API, which provides a large variety of datasets related to the Eenergy industry. From this source, we will get the actual spot price data over time, as well as time series data for following variables: \n",
    "\n",
    "Weekly inventory levels: \n",
    "\n",
    "The amount of crude oil in storage in the US for a given week. This basically serves as our measure of supply. \n",
    "\n",
    "U.S. Weekly product supplied:\n",
    "\n",
    "Measures the disappearance of petroleum products from primary sources; approximately represents consumption of petroleum products.\n",
    "\n",
    "We will also incorporate the Dow Jones Industrial Average in order to evaluate the relationship between crude oil prices and the performance of the broader market.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m \"precolab\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datashop import *\n",
    "from data_functions import *\n",
    "\n",
    "import pprint as pp\n",
    "\n",
    "import chart_studio.plotly as py\n",
    "\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.stattools import adfuller,kpss,coint,bds,q_stat,grangercausalitytests,levinson_durbin\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from statsmodels.tsa.statespace.tools import diff\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Capture \n",
    "eia_dict = {        \n",
    "        'DailyPrice':['DailyPrice','PET.RWTC.D','241335','%Y%m%d'],\n",
    "        'WeeklyStocks':['WeeklyStocks','PET.WTTSTUS1.W','235081','%Y%m%d'],\n",
    "        'ProductSupplied':['ProductSupplied', 'PET.WRPUPUS2.W','401676','%Y%m%d']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depot = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelimnary assesment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get the price data from the EIA, and study it by itself. We will try to find patterns in like like seasonality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprice = eia_dict['DailyPrice']\n",
    "\n",
    "price = EIA_Series(\n",
    "    dprice[1], \n",
    "    name = dprice[0],\n",
    "    date_format=dprice[3],\n",
    "    scale=True,\n",
    "    end='20200101'\n",
    "    )\n",
    "\n",
    "#\n",
    "\n",
    "data = [go.Scatter(x=price.scaled.index,\n",
    "            y=price.scaled)]\n",
    "\n",
    "fig = go.Figure(data)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Trends and Cycles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend and Cycles with Holdrick Prescott"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets examien the trend and cycle components for the whole series. We will first use the holdrick prescott filter to isolate the trend and cyclical components of the time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_cycle,price_trend = hpfilter(price.scaled,lamb=1600)\n",
    "\n",
    "price.frame['cycles'] = price_cycle\n",
    "price.frame['trend'] = price_trend\n",
    "\n",
    "data = [go.Scatter(x=price.scaled.index,\n",
    "            y=price.scaled, name = \"DailyPrice\"),\n",
    "        go.Scatter(x=price.frame.index,\n",
    "            y=price.frame['cycles'],name='Cycle'),\n",
    "        go.Scatter(x=price.frame.index,\n",
    "            y=price.frame['trend'],name = 'Trend')\n",
    "            ]\n",
    "\n",
    "fig = go.Figure(data)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = seasonal_decompose(\n",
    "    price.scaled, \n",
    "    model='additive',\n",
    "    period=365) \n",
    "\n",
    "result.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ETS plot shows us a few things that confirm our understanding of the evolution of oil price over time. \n",
    "\n",
    "The seasonality plot shows us that to some extent, the movement in oil prices is seasonal. This is probably due to increased demand during summer driving months or winter heating requirements. \n",
    "\n",
    "The error chart shows us the remaning movement, which cannot be explained by either the trends or the seasonality. And here we see again that there is more movement aorund 2008 and 2014 that cannot be explained by factors intrinsic to trends and seasonal fluctuations of oil. This confirms the idea that during these times, external factors strongly influences oil prices to move in unusual ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentially weighted moving average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the ways to mitigate the effects of extreme historical values is to use exponentially weighted moving averages instead of simple moving averages when trying to isolate trend components. Lets apply that to our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price.frame['EWM'] = price.frame[\"scaled_DailyPrice\"].ewm(span=365).mean()\n",
    "price.frame[['scaled_DailyPrice','EWM']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that EWM is not entirely sufficient to reduce the impact of the outlier events on the series."
   ]
  },
  {
   "source": [
    "# Exogenous Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depot = Depot()\n",
    "\n",
    "for key,val in eia_dict.items():\n",
    "    feature = EIA_Series(\n",
    "        val[1],\n",
    "        name=val[0],\n",
    "        date_format=val[3],\n",
    "        scale=True\n",
    "    )\n",
    "\n",
    "    depot.ingest(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depot.originals.dropna()"
   ]
  },
  {
   "source": [
    "# Forecasting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Lets proceed with building models to forecast future models. we will start with the Holt Winters methods for modeling time series, then try ARIMA, SARIMAX and VAR. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = price.frame.loc[:'20191001']\n",
    "test = price.frame.loc['20191002':]\n",
    "\n",
    "first_model = ExponentialSmoothing(\n",
    "    train['scaled_DailyPrice'],\n",
    "    trend='add',\n",
    "    seasonal='add',\n",
    "    seasonal_periods= 365\n",
    "    ).fit()\n",
    "predictions = first_model.forecast(92)\n",
    "\n",
    "data = [go.Scatter(x=predictions.index,\n",
    "            y=predictions, name = \"Predicted\"),\n",
    "        go.Scatter(x=test['scaled_DailyPrice'].index,\n",
    "            y=test['scaled_DailyPrice'],name='Actual')]\n",
    "fig = go.Figure(data)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "mse_error = mean_squared_error(test['scaled_DailyPrice'],predictions)\n",
    "rmse_error = rmse(test['scaled_DailyPrice'],predictions)\n",
    "\n",
    "print(\"Mean Squared Error: {}\".format(mse_error))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse_error))"
   ]
  },
  {
   "source": [
    "Our preliminary forecasting does not seem to be doing so well at first class. To an extent this was to be expected, since we have not yet factored in exogenous variables. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Holt Winters method"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ARIMA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Stationarity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Arima Order"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_arima(frame,seasonal=False).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price.frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = adfuller(price.scaled,autolag='AIC')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = price.scaled.diff().dropna()\n",
    "result = adfuller(frame,autolag='AIC')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = depot.scaled.dropna()\n",
    "frame = frame.diff().dropna()\n",
    "\n",
    "train = frame.loc['20150101':'20191001']\n",
    "test = frame.loc['20191002':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = frame.loc['20150101':'20191001']\n",
    "test = frame.loc['20191002':]\n",
    "\n",
    "first_model = SARIMAX(\n",
    "    train['scaled_DailyPrice'],\n",
    "    exog=train[['scaled_WeeklyStocks','scaled_ProductSupplied']],\n",
    "    order=(2,0,2)\n",
    "    ).fit()\n",
    "\n",
    "predictions = first_model.predict(\n",
    "    start='20191002',\n",
    "    end='20200101',\n",
    "    exog = test[['scaled_WeeklyStocks','scaled_ProductSupplied']].loc['20191002':'20200101'],\n",
    "    dynamic=False,typ='levels')\n",
    "\n",
    "data = [go.Scatter(x=predictions.index,\n",
    "            y=predictions, name = \"Predicted\"),\n",
    "        go.Scatter(x=test[['scaled_WeeklyStocks','scaled_ProductSupplied']].loc['20191002':'20200101'].index,\n",
    "            y=test[['scaled_WeeklyStocks','scaled_ProductSupplied']].loc['20191002':'20200101'],name='Actual')]\n",
    "fig = go.Figure(data)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "mse_error = mean_squared_error(test[['scaled_WeeklyStocks','scaled_ProductSupplied']].loc['20191002':'20200101'],predictions)\n",
    "rmse_error = rmse(testtest[['scaled_WeeklyStocks','scaled_ProductSupplied']].loc['20191002':'20200101'],predictions)\n",
    "\n",
    "print(\"Mean Squared Error: {}\".format(mse_error))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = frame.loc['20150101':'20191001']\n",
    "test = frame.loc['20191002':]\n",
    "\n",
    "first_model = SARIMAX(\n",
    "    train['scaled_DailyPrice'],\n",
    "    order=(2,0,2),\n",
    "    seasonal_order =(2,0,0,365)\n",
    "    ).fit()\n",
    "\n",
    "predictions = first_model.predict(\n",
    "    start='20191002',\n",
    "    end='20200101',\n",
    "    dynamic=False,typ='levels')\n",
    "\n",
    "data = [go.Scatter(x=predictions.index,\n",
    "            y=predictions, name = \"Predicted\"),\n",
    "        go.Scatter(x=test['scaled_DailyPrice'].loc['20191002':'20200101'].index,\n",
    "            y=test['scaled_DailyPrice'].loc['20191002':'20200101'],name='Actual')]\n",
    "fig = go.Figure(data)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "mse_error = mean_squared_error(test['scaled_DailyPrice'].loc['20191002':'20200101'],predictions)\n",
    "rmse_error = rmse(testtest['scaled_DailyPrice'].loc['20191002':'20200101'],predictions)\n",
    "\n",
    "print(\"Mean Squared Error: {}\".format(mse_error))\n",
    "print(\"Root Mean Squared Error: {}\".format(rmse_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}